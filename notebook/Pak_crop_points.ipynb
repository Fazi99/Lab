{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "id_path= \"/home/faizan/Desktop/shapefile/Pak_crop_points.csv\" \n",
    "csv_path = \"/home/faizan/HDD1/EVI/CSV/Pak_crop_all_point_evi.csv\"\n",
    "\n",
    "data1 = pd.read_csv(id_path)\n",
    "for i in range (1,49):\n",
    "    ind_path= \"/home/faizan/HDD1/EVI/CSV/Pak_crop_evi_%02d.csv\" % i\n",
    "    data = pd.read_csv(ind_path, header=None)\n",
    "    Id=[]\n",
    "    cnty=[]\n",
    "    lat=[]\n",
    "    lon=[]\n",
    "    typ=[]\n",
    "    for n in data.index:\n",
    "        Id.append(i)\n",
    "        cnty.append(\"Pak\")\n",
    "        lon.append(data1[\"X\"][i])\n",
    "        lat.append(data1[\"Y\"][i])\n",
    "        typ.append(data1[\"id\"][i])\n",
    "    data[2]=Id\n",
    "    data[3]=cnty\n",
    "    data[4]=typ\n",
    "    data[5]=lon\n",
    "    data[6]=lat\n",
    "    #data.columns = [\"DATE\",\"EVI\",\"ID\", \"CNTY\", \"TYP\",\"LON\", \"LAT\"]\n",
    "    #data.to_csv(csv_path, index=False)\n",
    "    data.to_csv(csv_path, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import time as t\n",
    "\n",
    "\n",
    "index_path= \"/home/faizan/HDD1/EVI/CSV/Pak_crop_all_point_evi.csv\"\n",
    "#yeild_path= \"/home/faizan/USA_data/index_output/US_near_yeild.csv\"\n",
    "pic_path = \"/home/faizan/HDD1/EVI/pics/\"\n",
    "ti= \"Time series of EVI at point \" \n",
    "\n",
    "CNTY = \"Pak\"\n",
    "\n",
    "if CNTY == \"Pak\":\n",
    "    R = 49\n",
    "    A , B = 2008 , 2013\n",
    "\n",
    "else:\n",
    "    R = 83\n",
    "    A , B = 2005 , 2010\n",
    "\n",
    "\n",
    "  \n",
    "for i in range (R):\n",
    "    \n",
    "    data = pd.read_csv(index_path)\n",
    "    data1 = data[data[\"ID\"] == i]\n",
    "    data1 = data1[data1[\"CNTY\"] == CNTY]\n",
    "    dates = [datetime.datetime.strptime(str(k), \"%Y%j\") for k in data1[\"DATE\"]]\n",
    "    data1.index = dates\n",
    "    dummy = data1[data1.index.year > A]\n",
    "    dummy = dummy[dummy.index.year < B]\n",
    "    time = dummy.index\n",
    "    evi  = dummy[\"EVI\"]/10000\n",
    "\n",
    "    lat=pd.Series.mean(data1[\"LAT\"])\n",
    "    lon=pd.Series.mean(data1[\"LON\"])\n",
    "    typ=pd.Series.mean(data1[\"TYP\"])\n",
    "    if typ == 1:\n",
    "        area=\"Desert\"\n",
    "    elif typ == 2:\n",
    "        area=  \"Crop\"\n",
    "    else:\n",
    "        area = \"River\"\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    lns1 = ax.plot(time, evi, 'r', label = 'EVI')\n",
    "    #ax2 = ax.twinx()\n",
    "    #lns5 = ax2.plot(time2, bs_hh , 'mo', label = 'bk_sct_hh')\n",
    "\n",
    "\n",
    "    # added these lines\n",
    "    lns = lns1\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax.legend(lns, labs, loc=2, prop={'size':10})\n",
    "    Title= ti + str(i)+ \" \" + CNTY +\" Type= \" +area +  \"\\n\" \" at Lat=\" +str(lat) + \" Lon=\" +str(lon) \n",
    "    ax.grid()\n",
    "    ax.set_title(Title)\n",
    "    ax.set_xlabel(\"Time (year)\")\n",
    "    ax.set_ylabel(\"evi\")\n",
    "    #ax2.set_ylabel(\"corr_backscatter\")\n",
    "    #ax2.set_ylim(0, -40)\n",
    "    ax.set_ylim(-0.5,1.2)\n",
    "    \n",
    "    pic= pic_path+ CNTY+\"_\"+str(i)+\"_flood.png\"\n",
    "    fig.savefig(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "id_path= \"/home/faizan/Desktop/shapefile/Pak_crop_points.csv\" \n",
    "#csv_path = \"/home/faizan/HDD1/CSV/cru_pak_all_point.csv\"\n",
    "\n",
    "data1 = pd.read_csv(id_path)\n",
    "dtype=[\"cld\", \"dtr\", \"frs\", \"pet\", \"pre\", \"tmn\", \"tmp\", \"tmx\", \"vap\", \"wet\"]\n",
    "for typ in dtype:\n",
    "    ty=typ\n",
    "    csv_path = \"/home/faizan/HDD1/CSV/cru_pak_all_point_%s.csv\" % typ\n",
    "    for i in range(0,49):\n",
    "        ind_path= \"/home/faizan/HDD1/CSV/cru_pak.%s.%02d.csv\" % (ty, i)\n",
    "        data = pd.read_csv(ind_path, header=None)\n",
    "        Id=[]\n",
    "        cnty=[]\n",
    "        lat=[]\n",
    "        lon=[]\n",
    "        typ=[]\n",
    "        for n in data.index:\n",
    "            Id.append(i)\n",
    "            cnty.append(\"Pak\")\n",
    "            lon.append(data1[\"X\"][i])\n",
    "            lat.append(data1[\"Y\"][i])\n",
    "            typ.append(data1[\"id\"][i ])\n",
    "        data[2]=Id\n",
    "        data[3]=cnty\n",
    "        data[4]=typ\n",
    "        data[5]=lon\n",
    "        data[6]=lat\n",
    "        #data.columns = [\"DATE\",\"EVI\",\"ID\", \"CNTY\", \"TYP\",\"LON\", \"LAT\"]\n",
    "        #data.to_csv(csv_path, index=False)\n",
    "        data.to_csv(csv_path, mode='a', index=False, header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "dtype=[\"dtr\", \"frs\", \"pet\", \"pre\", \"tmn\", \"tmp\", \"tmx\", \"vap\", \"wet\", \"cld\"]\n",
    "csv_path = \"/home/faizan/HDD1/CSV/cru_pak_all_points.csv\"\n",
    "data1 = pd.read_csv(csv_path, header=None)\n",
    "del data1[1]\n",
    "n=7\n",
    "for typ in dtype:\n",
    "    add_path = \"/home/faizan/HDD1/CSV/cru_pak_all_point_%s.csv\" % typ\n",
    "    data = pd.read_csv(add_path, header=None)\n",
    "    data1[n]=data[1]\n",
    "    n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1.columns = [\"DATE\",\"ID\",\"CNTY\",\"TYP\",\"LON\", \"LAT\",\"dtr\", \"frs\", \"pet\", \"pre\", \"tmn\", \"tmp\", \"tmx\", \"vap\", \"wet\", \"cld\" ]\n",
    "#data.to_csv(csv_path, index=False)\n",
    "#data1.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import time as t\n",
    "\n",
    "\n",
    "index_path= \"/home/faizan/HDD1/EVI/CSV/Pak_crop_all_point_evi.csv\"\n",
    "cl_path= \"/home/faizan/HDD1/CSV/cru_pak_all_points.csv\"\n",
    "pic_path = \"/home/faizan/HDD1/EVI/pics/\"\n",
    "ti= \"Time series of EVI at point \" \n",
    "dtype=[\"dtr\", \"frs\", \"pet\", \"pre\", \"tmn\", \"tmp\", \"tmx\", \"vap\", \"wet\", \"cld\"]\n",
    "\n",
    "for climate in dtype:\n",
    "\n",
    "    CNTY = \"Pak\"\n",
    "\n",
    "    if CNTY == \"Pak\":\n",
    "        R = 49\n",
    "        A , B = 2008 , 2013\n",
    "\n",
    "    else:\n",
    "        R = 83\n",
    "        A , B = 2005 , 2010\n",
    "\n",
    "    for i in range (R):\n",
    "\n",
    "        data = pd.read_csv(index_path)\n",
    "        data1 = data[data[\"ID\"] == i]\n",
    "        data1 = data1[data1[\"CNTY\"] == CNTY]\n",
    "        dates = [datetime.datetime.strptime(str(k), \"%Y%j\") for k in data1[\"DATE\"]]\n",
    "        data1.index = dates\n",
    "        dummy = data1[data1.index.year > A]\n",
    "        dummy = dummy[dummy.index.year < B]\n",
    "        time = dummy.index\n",
    "        evi  = dummy[\"EVI\"]/10000\n",
    "\n",
    "        data = pd.read_csv(cl_path)\n",
    "        data1 = data[data[\"ID\"] == i]\n",
    "        data1 = data1[data1[\"CNTY\"] == CNTY]\n",
    "        dates = [datetime.datetime.strptime(str(k), \"%Y%m\") for k in data1[\"DATE\"]]\n",
    "        data1.index = dates\n",
    "        dummy = data1[data1.index.year > A]\n",
    "        dummy = dummy[dummy.index.year < B]\n",
    "        time2 = dummy.index\n",
    "        cl_data = dummy[climate]\n",
    "\n",
    "        lat=pd.Series.mean(data1[\"LAT\"])\n",
    "        lon=pd.Series.mean(data1[\"LON\"])\n",
    "        typ=pd.Series.mean(data1[\"TYP\"])\n",
    "        if typ == 1:\n",
    "            area=\"Desert\"\n",
    "        elif typ == 2:\n",
    "            area=  \"Crop\"\n",
    "        else:\n",
    "            area = \"River\"\n",
    "\n",
    "        fig = plt.figure(figsize=(10,5))\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        lns1 = ax.plot(time, evi, 'r', label = 'EVI')\n",
    "        ax2 = ax.twinx()\n",
    "        lns2 = ax2.plot(time2, cl_data , 'mo', label = climate)\n",
    "\n",
    "\n",
    "        # added these lines\n",
    "        lns = lns1 + lns2\n",
    "        labs = [l.get_label() for l in lns]\n",
    "        ax.legend(lns, labs, loc=2, prop={'size':10})\n",
    "        Title= ti + str(i)+ \" \" + CNTY +\" Type= \" +area +  \"\\n\" \" at Lat=\" +str(lat) + \" Lon=\" +str(lon) \n",
    "        ax.grid()\n",
    "        ax.set_title(Title)\n",
    "        ax.set_xlabel(\"Time (year)\")\n",
    "        ax.set_ylabel(\"evi\")\n",
    "        ax2.set_ylabel(climate)\n",
    "        ax2.set_ylim(-5,5)\n",
    "        ax.set_ylim(-0.5,1.2)\n",
    "\n",
    "        pic= pic_path+ CNTY+\"_\"+str(i)+\"_\"+climate+\".png\"\n",
    "        fig.savefig(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import Image\n",
    "\n",
    "#opens an image:\n",
    "\n",
    "new_im = Image.new('RGB', (8190,4500))\n",
    "\n",
    "#Here I resize my opened image, so it is no bigger than 100,100\n",
    "#im.thumbnail((800,500))\n",
    "#Iterate through a 4 by 4 grid with 100 spacing, to place my image\n",
    "n = 0 \n",
    "for i in xrange(0,8190,910):   #810x500\n",
    "    for j in xrange(0,4500,500):\n",
    "           \n",
    "        im = Image.open(\"/home/faizan/USA_data/image_output/yeild_anomaly/US_all_near%s.png\" % n)\n",
    "#creates a new empty image, RGB mode, and size 400 by 400.\n",
    "        #I change brightness of the images, just to emphasise they are unique copies.\n",
    "                #paste the image at location i,j:\n",
    "        new_im.paste(im, (i,j))\n",
    "        n += 1\n",
    "        if n==82:\n",
    "            break \n",
    "new_im.save(\"/home/faizan/USA_data/image_output/yeild_anomaly/US_near_yeild.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import time as t\n",
    "\n",
    "\n",
    "index_path= \"/home/faizan/USA_data/index_output/all_year.csv\"\n",
    "yeild_path= \"/home/faizan/USA_data/index_output/US_far_yeild.csv\"\n",
    "pic_path = \"/home/faizan/USA_data/image_output/yeild_anomaly/\"\n",
    "ti= \"Time series of vegetation indices at point \" \n",
    "\n",
    "CNTY = \"US\"\n",
    "LOC = \"far\"\n",
    "\n",
    "if CNTY == \"Pak\":\n",
    "    if LOC == \"near\":\n",
    "        R = 80\n",
    "        A , B = 1999 , 2015\n",
    "    else:\n",
    "        R = 62\n",
    "        A , B = 1999 , 2015\n",
    "else:\n",
    "    if LOC == \"near\":\n",
    "        R = 83\n",
    "        A , B = 1999 , 2011\n",
    "    else:\n",
    "        R = 63\n",
    "        A , B = 1999 , 2011\n",
    "  \n",
    "for i in range (R):\n",
    "    \n",
    "    data = pd.read_csv(index_path)\n",
    "    \n",
    "    data1 = data[data[\"ID\"] == i]\n",
    "    data1 = data1[data1[\"CNTY\"] == CNTY]\n",
    "    data2 = data1[data1[\"LOC\"] == LOC]\n",
    "    data2 = data2[data2[\"EVI\"] >-999]\n",
    "    dates = [datetime.datetime.strptime(str(j[:10]), \"%Y-%m-%d\") for j in data2[\"DATE\"]]\n",
    "    data2.index = dates\n",
    "    dummy = data2\n",
    "    #dummy = data2[data2.index.year > A]\n",
    "    #dummy = dummy[dummy.index.year < B]\n",
    "    time = dummy.index\n",
    "    evi  = dummy[\"EVI\"]\n",
    "    ndvi = dummy[\"NDVI\"]\n",
    "    lswi = dummy[\"LSWI\"]\n",
    "    flood = dummy[\"FLOOD\"]\n",
    "    \n",
    "    lat=pd.Series.mean(data2[\"LAT\"])\n",
    "    lon=pd.Series.mean(data2[\"LON\"])\n",
    "    typ=pd.Series.mean(data2[\"TYP\"])\n",
    "    \n",
    "    data = pd.read_csv(yeild_path)\n",
    "    data1 = data[data[\"ID\"] == i]\n",
    "    dates = [datetime.datetime.strptime((str(j)+\"-11\"), \"%Y-%m\") for j in data1[\"year\"]]\n",
    "    data1.index = dates\n",
    "    dummy = data1\n",
    "    dummy = data1[data1.index.year > A]\n",
    "    dummy = dummy[dummy.index.year < B]\n",
    "    time2= dummy.index\n",
    "    yld = dummy[\"yield_anomaly\"]\n",
    "    #dates2 = [datetime.datetime.strptime(str(j+1), \"%Y\") for j in dummy[\"year\"]]\n",
    "    #time2=dates2\n",
    "    nor = []\n",
    "    for k in  range(len(dummy)):\n",
    "        time2\n",
    "        nor.append(1)\n",
    "\n",
    "    if typ == 1:\n",
    "        area=\"Water\"\n",
    "    elif typ == 2:\n",
    "        area=  \"Crop\"\n",
    "    elif typ == 3:\n",
    "        area= \"Flooded Crop\"\n",
    "    else:\n",
    "        area = \"Desert\"\n",
    "\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    lns1 = ax.plot(time, evi, 'r', label = 'evi')\n",
    "    lns2 = ax.plot(time, lswi, 'b', label = 'lswi')\n",
    "    lns3 = ax.plot(time, ndvi, 'c', label = 'ndvi')\n",
    "    lns4 = ax.plot(time, flood, 'g', label = 'flood')\n",
    "    ax2 = ax.twinx()\n",
    "    lns5 = ax2.plot(time2, yld , 'ro', label = 'yield_anomaly')\n",
    "    lns6 = ax2.plot(time2, nor , 'k', label = 'normal')\n",
    "\n",
    "    # added these lines\n",
    "    lns = lns1+lns2+lns3+lns4+lns5+lns6\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax.legend(lns, labs, loc=2, prop={'size':10})\n",
    "    Title= ti + str(i)+ \" \" + CNTY +\" \"+ LOC+ \" Type= \" +area +  \"\\n\" \" at Lat=\" +str(lat) + \" Lon=\" +str(lon) \n",
    "    ax.grid()\n",
    "    ax.set_title(Title)\n",
    "    ax.set_xlabel(\"Time (year)\")\n",
    "    ax.set_ylabel(\"evi, lswi, ndvi, flood\")\n",
    "    ax2.set_ylabel(\"Yield_anomaly\")\n",
    "    ax2.set_ylim(0.5, 1.5)\n",
    "    ax.set_ylim(-0.5,1.2)\n",
    "    \n",
    "    pic= pic_path+ CNTY+\"_all_\"+LOC+str(i)+\".png\"\n",
    "    fig.savefig(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'h'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d2c858712586>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m01\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'h'"
     ]
    }
   ],
   "source": [
    "\n",
    "y = 2000\n",
    "h = 01\n",
    "c = y.h\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import Image\n",
    "import  os\n",
    "#opens an image:\n",
    "\n",
    "new_im = Image.new('RGB', (5600,10400))\n",
    "\n",
    "#Here I resize my opened image, so it is no bigger than 100,100\n",
    "#im.thumbnail((800,500))\n",
    "#Iterate through a 4 by 4 grid with 100 spacing, to place my image\n",
    "n = 0 \n",
    "for i in xrange(0,5600,1400):   #810x500\n",
    "    for j in xrange(0,3000,500):\n",
    "        if os.path.exists(\"/home/faizan/USA_data/image_output/yeild_anomaly1/US_all_near%s.png\" % n) is True:\n",
    "           \n",
    "            im = Image.open(\"/home/faizan/USA_data/image_output/yeild_anomaly1/US_all_near%s.png\" % n)\n",
    "    #creates a new empty image, RGB mode, and size 400 by 400.\n",
    "            #I change brightness of the images, just to emphasise they are unique copies.\n",
    "                    #paste the image at location i,j:\n",
    "        new_im.paste(im, (i,j))\n",
    "        n += 1\n",
    "        if n==26:\n",
    "            break \n",
    "new_im.save(\"/home/faizan/USA_data/image_output/yeild_anomaly1/US_yeild_near.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import Image\n",
    "import  os\n",
    "#opens an image:\n",
    "\n",
    "new_im = Image.new('RGB', (5600,3000))\n",
    "\n",
    "#Here I resize my opened image, so it is no bigger than 100,100\n",
    "#im.thumbnail((800,500))\n",
    "#Iterate through a 4 by 4 grid with 100 spacing, to place my image\n",
    "n = 0 \n",
    "Array= []\n",
    "for K in range(63):\n",
    "    if os.path.exists(\"/home/faizan/USA_data/image_output/yeild_anomaly1/US_all_far%s.png\" % n) is True:\n",
    "        Array.append(\"/home/faizan/USA_data/image_output/yeild_anomaly1/US_all_far%s.png\" % n) \n",
    "    n += 1 \n",
    "k = 0\n",
    "for i in xrange(0,5600,1400):   #810x500\n",
    "    for j in xrange(0,3000,500):\n",
    "        im = Image.open(Array[k])\n",
    "    #creates a new empty image, RGB mode, and size 400 by 400.\n",
    "            #I change brightness of the images, just to emphasise they are unique copies.\n",
    "                    #paste the image at location i,j:\n",
    "        new_im.paste(im, (i,j))\n",
    "        k += 1    \n",
    "        if k==len(Array):\n",
    "            break \n",
    "new_im.save(\"/home/faizan/USA_data/image_output/yeild_anomaly1/US_yeild_far.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/faizan/USA_data/image_output/yeild_anomaly1/US_all_near0.png'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Array[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import Image\n",
    "import  os\n",
    "#opens an image:\n",
    "\n",
    "new_im = Image.new('RGB', (5600,3500))\n",
    "\n",
    "#Here I resize my opened image, so it is no bigger than 100,100\n",
    "#im.thumbnail((800,500))\n",
    "#Iterate through a 4 by 4 grid with 100 spacing, to place my image\n",
    "n = 0 \n",
    "for K in range(63):\n",
    "    if os.path.exists(\"/home/faizan/USA_data/image_output/yeild_anomaly1/US_all_far%s.png\" % n) is True:\n",
    "        for i in xrange(0,5600,1400):   #810x500\n",
    "            for j in xrange(0,3500,500):\n",
    "                im = Image.open(\"/home/faizan/USA_data/image_output/yeild_anomaly1/US_all_far%s.png\" % n)\n",
    "            #creates a new empty image, RGB mode, and size 400 by 400.\n",
    "                    #I change brightness of the images, just to emphasise they are unique copies.\n",
    "                            #paste the image at location i,j:\n",
    "                new_im.paste(im, (i,j))\n",
    "        n += 1\n",
    "    n += 1    \n",
    "    if n==83:\n",
    "        break \n",
    "new_im.save(\"/home/faizan/USA_data/image_output/yeild_anomaly1/US_yeild_far.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import time as t\n",
    "\n",
    "\n",
    "index_path= \"/home/faizan/USA_data/index_output/all_year.csv\"\n",
    "yeild_path= \"/home/faizan/USA_data/index_output/US_far_yeild.csv\"\n",
    "pic_path = \"/home/faizan/USA_data/image_output/yeild_anomaly/\"\n",
    "ti= \"Time series of vegetation indices, flood and yeild \" \n",
    "\n",
    "CNTY = \"US\"\n",
    "LOC = \"near\"\n",
    "\n",
    "if CNTY == \"Pak\":\n",
    "    if LOC == \"near\":\n",
    "        R = 80\n",
    "        A , B = 2001 , 2015\n",
    "    else:\n",
    "        R = 62\n",
    "        A , B = 1999 , 2015\n",
    "else:\n",
    "    if LOC == \"near\":\n",
    "        R = 83\n",
    "        A , B = 2000 , 2004\n",
    "    else:\n",
    "        R = 63\n",
    "        A , B = 1999 , 2011\n",
    "  \n",
    "for i in range (33,34):\n",
    "    \n",
    "    data = pd.read_csv(index_path)\n",
    "    \n",
    "    data1 = data[data[\"ID\"] == i]\n",
    "    data1 = data1[data1[\"CNTY\"] == CNTY]\n",
    "    data2 = data1[data1[\"LOC\"] == LOC]\n",
    "    data2 = data2[data2[\"EVI\"] >-999]\n",
    "    dates = [datetime.datetime.strptime(str(j[:10]), \"%Y-%m-%d\") for j in data2[\"DATE\"]]\n",
    "    data2.index = dates\n",
    "    dummy = data2\n",
    "    dummy = data2[data2.index.year > A]\n",
    "    dummy = dummy[dummy.index.year < B]\n",
    "    time = dummy.index\n",
    "    evi  = dummy[\"EVI\"]\n",
    "    ndvi = dummy[\"NDVI\"]\n",
    "    lswi = dummy[\"LSWI\"]\n",
    "    flood = dummy[\"FLOOD\"]\n",
    "    \n",
    "    lat=pd.Series.mean(data2[\"LAT\"])\n",
    "    lon=pd.Series.mean(data2[\"LON\"])\n",
    "    typ=pd.Series.mean(data2[\"TYP\"])\n",
    "    \n",
    "    data = pd.read_csv(yeild_path)\n",
    "    data1 = data[data[\"ID\"] == i]\n",
    "    dates = [datetime.datetime.strptime((str(j)+\"-11\"), \"%Y-%m\") for j in data1[\"year\"]]\n",
    "    data1.index = dates\n",
    "    dummy = data1\n",
    "    dummy2 = data1[data1.index.year > (A-1)]\n",
    "    dummy2 = dummy2[dummy2.index.year < B]\n",
    "    time1= dummy2.index\n",
    "    dummy = data1[data1.index.year > A]\n",
    "    dummy = dummy[dummy.index.year < B]\n",
    "    time2= dummy.index\n",
    "    yld = dummy[\"yield_anomaly\"]\n",
    "    #dates2 = [datetime.datetime.strptime(str(j+1), \"%Y\") for j in dummy[\"year\"]]\n",
    "    #time2=dates2\n",
    "    nor = []\n",
    "    for k in  range(len(dummy2)):\n",
    "        time1\n",
    "        nor.append(1)\n",
    "\n",
    "    if typ == 1:\n",
    "        area=\"Water\"\n",
    "    elif typ == 2:\n",
    "        area=  \"Crop\"\n",
    "    elif typ == 3:\n",
    "        area= \"Flooded Crop\"\n",
    "    else:\n",
    "        area = \"Desert\"\n",
    "\n",
    "    fig = plt.figure(figsize=(7,6.5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    lns1 = ax.plot(time, evi, 'b', label = 'evi')\n",
    "    #lns2 = ax.plot(time, lswi, 'b', label = 'lswi')\n",
    "    #lns3 = ax.plot(time, ndvi, 'c', label = 'ndvi')\n",
    "    lns4 = ax.plot(time, flood, 'g', label = 'flood')\n",
    "    ax2 = ax.twinx()\n",
    "    lns5 = ax2.plot(time2, yld , 'ro', label = 'yield_anomaly')\n",
    "    lns6 = ax2.plot(time1, nor , 'r--', label = 'normal')\n",
    "\n",
    "    # added these lines\n",
    "    lns = lns1+lns4+lns5+lns6\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax.legend(lns, labs, loc=2, prop={'size':14})\n",
    "    Title= ti \n",
    "    ax.grid()\n",
    "    ax.set_title(Title, fontsize=16)\n",
    "    ax.set_xlabel(\"Time\", fontsize=12)\n",
    "    ax.set_ylabel(\"evi, flood\" ,fontsize=12)\n",
    "    ax2.set_ylabel(\"Yield_anomaly\", fontsize=12)\n",
    "    ax2.set_ylim(0.6, 1.5)\n",
    "    ax.set_ylim(-0.2,1.2)\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(10) \n",
    "                tick.label.set_rotation(45)\n",
    "    pic= pic_path+\"y1.png\"\n",
    "    fig.savefig(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
